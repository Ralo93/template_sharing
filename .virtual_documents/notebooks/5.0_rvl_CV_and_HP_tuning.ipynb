import pandas as pd
import os
import numpy as np


from catboost import CatBoostClassifier
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score


x = pd.read_csv(r'../data/interim/xinit.csv')
y = pd.read_csv(r'../data/interim/yinit.csv')

x['bmi'] = (x['Weight'] / x['Height'] ** 2)

#x = x.drop('Weight', axis=1)


# Select categorical columns with relatively low cardinality (convenient but arbitrary)
categorical_cols = [cname for cname in x.columns if x[cname].nunique() < 8 and x[cname].dtype == "object"]

# Select numerical columns
numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int64', 'float64']]


categorical_cols


numerical_cols


#create numerical transformer
numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean')), 
                                  ('scaler', StandardScaler()) ])

#create categorical transformer
categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),
                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))
                                            ])


preprocessor = ColumnTransformer(
                                transformers=[
                                    ('num', numerical_transformer, numerical_cols),
                                    ('cat', categorical_transformer, categorical_cols)
    ])


X_train = pd.read_csv(r'../data/interim/x_train_init.csv')
X_test = pd.read_csv(r'../data/interim/x_test_init.csv')
y_train = pd.read_csv(r'../data/interim/y_train_init.csv')
y_test = pd.read_csv(r'../data/interim/y_test_init.csv')


X_train['bmi'] = (X_train['Weight'] / X_train['Height'] ** 2)
X_test['bmi'] = (X_test['Weight'] / X_test['Height'] ** 2)
#X_train = X_train.drop('Weight', axis=1)
#X_test = X_test.drop('Weight', axis=1)


# Create a CatBoostClassifier model
cb = CatBoostClassifier(
    iterations=300,        # Equivalent to n_estimators
    learning_rate=0.1,
    depth=5,
    random_state=42,
    verbose=0               # Suppress training output
)

# Model pipeline
# Create pipeline
rf_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('catboost', cb)
])

# Preprocessing of training data, fit model 
rf_pipe.fit(X_train, y_train)

# Preprocessing of validation data, get predictions
rf_preds = rf_pipe.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, rf_preds)
print('Accuracy for Catboost:', accuracy)

# Detailed classification report
print('Classification Report:\n', classification_report(y_test, rf_preds))



import plotly.graph_objects as go
# Get feature names from the preprocessor
feature_names = preprocessor.get_feature_names_out()


importances = cb.feature_importances_

# Get the feature importances from the Random Forest model
# Create a dictionary mapping feature names to their importances
feature_importance_dict = dict(zip(feature_names, importances))

# Optional: Sort the dictionary by importance in descending order
feature_importance_sorted = dict(sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True))

fig = go.Figure(data=[
        go.Bar(
            x=list(feature_importance_sorted.keys()),
            y=list(feature_importance_sorted.values()),
            marker=dict(color='skyblue'),
            text=[f"{v:.3f}" for v in feature_importance_sorted.values()],
            textposition='auto'
        )
    ])

# Update layout for better aesthetics
fig.update_layout(
    title='Feature Importances from CatBoost',
    xaxis_title='Features',
    yaxis_title="Importance Score",
    template='plotly_white',
    height=600
)

# Display the figure
fig.show()


crv_scores_cb = cross_val_score(rf_pipe, x, y,
                                cv=5,
                                scoring='accuracy')

print("Accuracy from Cross Validation (CatBoost):", crv_scores_cb)
print("Mean Accuracy:", crv_scores_cb.mean())
print("Standard Deviation:", crv_scores_cb.std())


from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

# Define the hyperparameter space for CatBoost
param_dist = {
    'catboost__iterations': randint(100, 500),            # Number of trees
    'catboost__learning_rate': uniform(0.01, 0.29),       # Learning rate between 0.01 and 0.3
    'catboost__depth': randint(3, 10),                    # Depth of trees
    'catboost__l2_leaf_reg': uniform(1, 10),              # L2 regularization term
    'catboost__border_count': randint(32, 255),           # Number of splits for numerical features
    'catboost__bagging_temperature': uniform(0, 1),       # Controls the intensity of Bayesian bagging
    'catboost__random_strength': uniform(1, 10),          # Standard deviation of the Gaussian prior on weights
    'catboost__od_type': ['IncToDec', 'Iter', 'IterWithoutNeighbors'],  # Overfitting detector types
    'catboost__od_wait': randint(10, 50)                  # Number of iterations to wait for improvement
}



# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=rf_pipe,               # The pipeline to optimize
    param_distributions=param_dist,  # The hyperparameter space
    n_iter=30,                        # Number of parameter settings sampled
    cv=5,                             # 5-fold cross-validation
    scoring='accuracy',               # Evaluation metric
    random_state=42,                  # Ensures reproducibility
    n_jobs=-1,                        # Use all available cores
    verbose=1                         # Displays progress
)

# Perform the random search on the training data
random_search.fit(X_train, y_train)



# Best hyperparameters
print("Best Hyperparameters:\n", random_search.best_params_)

# Best cross-validation score
print("Best Cross-Validation Accuracy:", random_search.best_score_)

# Evaluate the best model on the test set
best_model = random_search.best_estimator_

# Make predictions
best_preds = best_model.predict(X_test)

# Calculate accuracy
best_accuracy = accuracy_score(y_test, best_preds)
print('Test Set Accuracy for Best CatBoost Model:', best_accuracy)

# Detailed classification report
print('Classification Report for Best CatBoost Model:\n', classification_report(y_test, best_preds))




