import pandas as pd
import os
import numpy as np
import sys
sys.path.append('..')


data = pd.read_csv(r'../data/interim/promotion/train_clean.csv')


test_data = pd.read_csv(r'../data/raw/promotion/test.csv')


data.columns


test_data.columns


test_data = test_data.drop(columns=['EmployeeNo', 'Past_Disciplinary_Action'])
x_test = test_data
#y = data.Promoted_or_Not


x = data.drop(columns=['Promoted_or_Not'])
y = data.Promoted_or_Not
y


numerical_df = data.select_dtypes(exclude=['object'])
categorical_df = data.select_dtypes(include=['object'])


# Select categorical columns with relatively low cardinality (convenient but arbitrary)
categorical_cols = [cname for cname in x.columns if x[cname].nunique() < 800 and x[cname].dtype == "object"]

# Select numerical columns
numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int64', 'float64']]


from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler, MinMaxScaler

#train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)


from category_encoders import BaseNEncoder


from src.eda_first import summarize_dataframe
summarize_dataframe(data)


data.Promoted_or_Not.value_counts()


#create numerical transformer


numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean')), 
                                  ('scaler', StandardScaler()) ])

#create categorical transformer
categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),
                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))
                                            ])

base_encoder_columns = ['Division', 'Qualification', 'Channel_of_Recruitment', 'State_Of_Origin', 'Foreign_schooled', 'Marital_Status', 'Previous_IntraDepartmental_Movement', 'No_of_previous_employers', 'Gender']
base_encoder = Pipeline(steps=[
    ('base_encoder', BaseNEncoder(cols=base_encoder_columns, base=3))
])


# Combine the transformations using ColumnTransformer
preprocessor = ColumnTransformer(transformers=[
    ('base_name', base_encoder, base_encoder_columns),  # TargetEncoder for 'town'
    ('num', numerical_transformer, numerical_cols)
])





from sklearn.utils import resample

# Combine features and target into a single DataFrame for resampling
df_train = pd.concat([X_train, y_train], axis=1)

# Identify the majority and minority classes
majority_class = df_train[df_train['Promoted_or_Not'] == 0]
minority_class = df_train[df_train['Promoted_or_Not'] == 1]

# Upsample the minority class
minority_class_upsampled = resample(
    minority_class,
    replace=True,            # Sample with replacement
    n_samples=len(majority_class),  # Match majority class
    random_state=42          # For reproducibility
)

# Combine majority class with upsampled minority class
df_upsampled = pd.concat([majority_class, minority_class_upsampled])

# Shuffle the dataset
df_upsampled = df_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)

# Separate features and target again
X_train_upsampled = df_upsampled.drop('Promoted_or_Not', axis=1)
y_train_upsampled = df_upsampled['Promoted_or_Not']



X_train_upsampled.describe()



from src.plots import create_feature_subplots
from src.plots import create_scatter_plot
# Example usage:
# Assuming 'data' is your DataFrame with numerical and categorical features
#fig = create_feature_subplots(y_train_upsampled)
#print(data.price)
y_train_upsampled.value_counts()


y_train.value_counts()





import numpy as np

# Example y array (your class labels)
y = y_train  # Replace with your actual labels

# Count occurrences of each class
count_class_0 = np.sum(y == 0)  # Majority class (negative class)
count_class_1 = np.sum(y == 1)  # Minority class 1
count_class_2 = np.sum(y == 2)  # Minority class 2

# Compute scale_pos_weight (sum of negative instances / sum of positive instances)
# This is typically used to weigh the positive classes against the majority class (class 0).
sum_positive_classes = count_class_1 + count_class_2
sum_negative_class = count_class_0

scale_pos_weight = sum_negative_class / sum_positive_classes if sum_positive_classes != 0 else 0

print(f"Scale pos weight: {scale_pos_weight}")



from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier
# XGBoost
xgb = XGBClassifier(
    n_estimators=339,
    learning_rate=0.2669112505018992,
    max_depth=5,
    random_state=42,
    reg_lambda=1.2259716591605452,
    subsample=0.704976942819638,
    colsample_bytree=0.9,
    alpha= 0.14170716330946964,    # Added L1 regularization
    #reg_lambda=1,   # Added L2 regularization (can also be increased)
    eval_metric='mlogloss'
)

# Model pipeline
rf_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('xgboost', xgb)
])

# Preprocessing of training data, fit model 
#rf_pipe.fit(X_train, y_train)

# Preprocessing of training data, fit model after upsampling!
rf_pipe.fit(X_train_upsampled, y_train_upsampled)

# Preprocessing of validation data, get predictions
rf_preds = rf_pipe.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, rf_preds)
print('Accuracy for XGBoost:', accuracy)

# Detailed classification report
print('Classification Report:\n', classification_report(y_test, rf_preds))





rf_preds = rf_pipe.predict(X_train_upsampled)

# Evaluate the model
accuracy = accuracy_score(y_train_upsampled, rf_preds)
print('Accuracy for Random Forest Model:', accuracy)

# Detailed classification report
print('Classification Report:\n', classification_report(y_train_upsampled, rf_preds))






from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import cross_val_score

crv_scores_cb = cross_val_score(rf_pipe, x, y,
                                cv=5,
                                scoring='accuracy')

print("Accuracy from Cross Validation (XGBoost):", crv_scores_cb)
print("Mean Accuracy:", crv_scores_cb.mean())
print("Standard Deviation:", crv_scores_cb.std())





rf_preds = rf_pipe.predict(test_data)

# Evaluate the model
accuracy = accuracy_score(y_train_upsampled, rf_preds)
print('Accuracy for Random Forest Model:', accuracy)

# Detailed classification report
print('Classification Report:\n', classification_report(y_train_upsampled, rf_preds))



import plotly.graph_objects as go
# Get feature names from the preprocessor
feature_names = preprocessor.get_feature_names_out()

importances = xgb.feature_importances_

# Get the feature importances from the Random Forest model
# Create a dictionary mapping feature names to their importances
feature_importance_dict = dict(zip(feature_names, importances))

# Optional: Sort the dictionary by importance in descending order
feature_importance_sorted = dict(sorted(feature_importance_dict.items(), key=lambda item: item[1], reverse=True))

fig = go.Figure(data=[
        go.Bar(
            x=list(feature_importance_sorted.keys()),
            y=list(feature_importance_sorted.values()),
            marker=dict(color='skyblue'),
            text=[f"{v:.3f}" for v in feature_importance_sorted.values()],
            textposition='auto'
        )
    ])

# Update layout for better aesthetics
fig.update_layout(
    title='Feature Importances from Random Forest',
    xaxis_title='Features',
    yaxis_title="Importance Score",
    template='plotly_white',
    height=600
)

# Display the figure
fig.show()



